{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f763d8a9",
   "metadata": {},
   "source": [
    "# In this project We have used 22 features from EEG Signals to predict the six Emotion classes.\n",
    "1. We have used Random forest classifier with 10 Fold Cross Validation\n",
    "2. Best training split is giving mean classwise validation accuracy as 0.2555 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2288c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8405a2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 4500, 24), (180, 4500, 24), (360,), (180,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_360_array=np.load('TrainRawDataArray/Train_RawEEG360_Data.npy')\n",
    "val_180_array=np.load('ValidationRawDataArray/Validation_RawEEG180_Data.npy')\n",
    "train_labels=np.load('TrainRawDataArray/final_labels_360_encoded.npy')\n",
    "val_labels=np.load('ValidationRawDataArray//val_labels_encoded.npy')\n",
    "\n",
    "train_360_array.shape, val_180_array.shape,train_labels.shape,val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f597d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "def classwise_accuracy(y_true, y_pred):\n",
    "    # Calculate overall accuracy\n",
    "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Calculate class-wise accuracy\n",
    "    classwise_accuracy = np.diag(cm) / cm.sum(axis=1)\n",
    "    \n",
    "    return overall_accuracy, classwise_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f335e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "from mne.io import read_raw_edf\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pywt\n",
    "from scipy.signal import find_peaks, peak_widths \n",
    "\n",
    "def calculate_eeg_features(eeg_data, sampling_freq):\n",
    "    # Welch's method for calculating power spectral density\n",
    "    f_welch, psd_welch = welch(eeg_data, fs=sampling_freq, nperseg=256)\n",
    "    \n",
    "    # Handle the case where welch returns only a single array\n",
    "    if len(psd_welch.shape) == 1:  \n",
    "        psd_welch = psd_welch[np.newaxis, :]\n",
    "    \n",
    "    # Total power using Welch's method\n",
    "    total_power_welch = np.sum(psd_welch)\n",
    "    \n",
    "    # Skewness and kurtosis of EEG signal\n",
    "    skewness = skew(eeg_data)\n",
    "    kurt = kurtosis(eeg_data)\n",
    "    \n",
    "    # Mean, median, variance, and standard deviation of EEG signal\n",
    "    mean_val = np.mean(eeg_data)\n",
    "    median_val = np.median(eeg_data)\n",
    "    variance_val = np.var(eeg_data)\n",
    "    std_deviation = np.std(eeg_data)\n",
    "    \n",
    "    # Wavelet entropy of EEG signal\n",
    "    coeffs = pywt.wavedec(eeg_data, 'db4', level=6)\n",
    "    wave_ent = np.sum([np.sum(np.square(c)) for c in coeffs])\n",
    "    \n",
    "    # Calculate power in different frequency bands\n",
    "    freqs = f_welch\n",
    "    delta_power = np.sum(psd_welch[:, (freqs >= 0.5) & (freqs < 4)], axis=1).item()\n",
    "    theta_power = np.sum(psd_welch[:, (freqs >= 4) & (freqs < 8)], axis=1).item()\n",
    "    alpha_power = np.sum(psd_welch[:, (freqs >= 8) & (freqs < 13)], axis=1).item()\n",
    "    beta_power = np.sum(psd_welch[:, (freqs >= 13) & (freqs < 30)], axis=1).item()\n",
    "    gamma_power = np.sum(psd_welch[:, (freqs >= 30) & (freqs < 45)], axis=1).item()\n",
    "    sigma_power = np.sum(psd_welch[:, (freqs >= 12) & (freqs < 16)], axis=1).item()\n",
    "    \n",
    "    # Additional frequency band features\n",
    "    theta_alpha_ratio = np.divide(theta_power, alpha_power, out=np.zeros_like(theta_power), where=(alpha_power != 0))\n",
    "    beta_alpha_ratio = np.divide(beta_power, alpha_power, out=np.zeros_like(beta_power), where=(alpha_power != 0))\n",
    "    theta_alpha_beta_sum = np.divide((theta_power + alpha_power), beta_power, out=np.zeros_like(beta_power), where=(beta_power != 0))\n",
    "    \n",
    "\n",
    "    # Zero-crossing rate\n",
    "    zero_crossings = np.sum(np.diff(np.sign(eeg_data)) != 0) / len(eeg_data)\n",
    "    \n",
    "    # Number of waves\n",
    "    peaks, _ = find_peaks(eeg_data)\n",
    "    num_waves = len(peaks)\n",
    "    \n",
    "    # Wave duration\n",
    "    peak_widths_arr = peak_widths(eeg_data, peaks, rel_height=0.5)\n",
    "    wave_duration = np.mean(peak_widths_arr[0] / sampling_freq)\n",
    "    \n",
    "    # Peak amplitude\n",
    "    peak_amplitude = np.max(eeg_data)\n",
    "    \n",
    "    # Energy\n",
    "    energy = np.sum(np.square(eeg_data))\n",
    "    \n",
    "    return np.array([total_power_welch, skewness, kurt, mean_val, median_val, variance_val, std_deviation, wave_ent, delta_power, theta_power, alpha_power, beta_power, gamma_power, sigma_power, theta_alpha_ratio, beta_alpha_ratio, theta_alpha_beta_sum,zero_crossings,num_waves,wave_duration,peak_amplitude,energy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fcdb393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 4500, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array_180x4500x24=np.load('TestRawDataArray/test_array_180x4500x24.npy')\n",
    "test_array_180x4500x24.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19773f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Transposed Shape:  (360, 24, 4500)\n",
      "Validation Transposed Shape:  (180, 24, 4500)\n",
      "Test Data Transposed Shape:  (180, 24, 4500)\n",
      "Train Reshaped:  (8640, 4500)\n",
      "Validation Reshaped:  (4320, 4500)\n",
      "Test Data Reshaped:  (4320, 4500)\n"
     ]
    }
   ],
   "source": [
    "train_360_eeg_transpose=np.transpose(train_360_array, (0, 2, 1))\n",
    "val_180_eeg_transpose=np.transpose(val_180_array, (0, 2, 1))\n",
    "test_360_eeg_transpose=np.transpose(test_array_180x4500x24, (0, 2, 1))\n",
    "print(\"Train Transposed Shape: \",train_360_eeg_transpose.shape)\n",
    "print(\"Validation Transposed Shape: \",val_180_eeg_transpose.shape)\n",
    "print(\"Test Data Transposed Shape: \",test_360_eeg_transpose.shape)\n",
    "\n",
    "train_eegData360_reshaped=train_360_eeg_transpose.reshape(-1,4500)\n",
    "val_eegData180_reshaped=val_180_eeg_transpose.reshape(-1,4500)\n",
    "test_eegData180_reshaped=test_360_eeg_transpose.reshape(-1,4500)\n",
    "\n",
    "print(\"Train Reshaped: \",train_eegData360_reshaped.shape)\n",
    "print(\"Validation Reshaped: \",val_eegData180_reshaped.shape)\n",
    "print(\"Test Data Reshaped: \",test_eegData180_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cac5f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSE\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\CSE\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8640, 4320, 4320)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_22=[]\n",
    "val_features_22=[]\n",
    "test_features_22=[]\n",
    "\n",
    "sampling_freq=300\n",
    "\n",
    "for i in train_eegData360_reshaped:\n",
    "    train_features_array= calculate_eeg_features(i, sampling_freq)\n",
    "    train_features_22.append(train_features_array)\n",
    "    \n",
    "for j in val_eegData180_reshaped:\n",
    "    val_features_array=calculate_eeg_features(j, sampling_freq)\n",
    "    val_features_22.append(val_features_array)\n",
    "\n",
    "for k in test_eegData180_reshaped:\n",
    "    test_features_array=calculate_eeg_features(k, sampling_freq)\n",
    "    test_features_22.append(test_features_array)\n",
    "    \n",
    "len(train_features_22), len(val_features_22), len(test_features_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4a237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Features Shape:  (8640, 22)\n",
      "Validation Features Shape:  (4320, 22)\n",
      "Test Features Shape:  (4320, 22)\n"
     ]
    }
   ],
   "source": [
    "train_22Features=np.array(train_features_22)\n",
    "val_22Features=np.array(val_features_22)\n",
    "test_22Features=np.array(test_features_22)\n",
    "print(\"Train Features Shape: \", train_22Features.shape)\n",
    "print(\"Validation Features Shape: \", val_22Features.shape)\n",
    "print(\"Test Features Shape: \", test_22Features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa12a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's np.isnan  : 2\n",
      "It's np.isnan  : 0\n"
     ]
    }
   ],
   "source": [
    "## Checking NaN values and Replacing in the Train Features data  {There are 2 NaN values in the Train Data}\n",
    "\n",
    "print(f\"It's np.isnan  : {np.isnan(train_22Features).sum()}\")\n",
    "train_22features_withoutNan=np.nan_to_num(train_22Features, np.nanmean(train_features_22))\n",
    "print(f\"It's np.isnan  : {np.isnan(train_22features_withoutNan).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f2f8105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's np.isnan  : 5\n",
      "It's np.isnan  : 0\n"
     ]
    }
   ],
   "source": [
    "## Checking NaN values and Replacing in the Validation features data  {There are 5 NaN values in the Validation data}\n",
    "\n",
    "print(f\"It's np.isnan  : {np.isnan(val_22Features).sum()}\")\n",
    "\n",
    "val_22features_withoutNan=np.nan_to_num(val_22Features, np.nanmean(val_features_22)) \n",
    "\n",
    "print(f\"It's np.isnan  : {np.isnan(val_22features_withoutNan).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4452b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's np.isnan  : 0\n"
     ]
    }
   ],
   "source": [
    "#   Checking NaN in the test features {There is No NaN value in test data}\n",
    "\n",
    "print(f\"It's np.isnan  : {np.isnan(test_22Features).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d2fbaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Reshaped 22 Features:  (360, 24, 22)\n",
      "Validation Reshaped 22 Features:  (180, 24, 22)\n",
      "Test Reshaped 22 Features:  (180, 24, 22)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping Train, Validation and Test data into the original shape {i.e. Train: 360x24x22, Val:180x24x22, Test:180x24x22 } \n",
    "\n",
    "train_22features_reshaped = train_22features_withoutNan.reshape(360,24, 22)  # will have a shape of (380*24, 22)\n",
    "val_22features_reshaped = val_22features_withoutNan.reshape(180,24, 22)\n",
    "test_22features_reshaped = test_22Features.reshape(180,24, 22)\n",
    "\n",
    "print(\"Train Reshaped 22 Features: \", train_22features_reshaped.shape)\n",
    "print(\"Validation Reshaped 22 Features: \", val_22features_reshaped.shape)\n",
    "print(\"Test Reshaped 22 Features: \", test_22features_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1f9fd8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Best indexes Shape:  (324,)\n",
      "Test Best indexes shape:  (36,)\n"
     ]
    }
   ],
   "source": [
    "# Loading the Indexes of Best Split of Train Data Saved at the time 10 fold cross validation\n",
    "# Split-0 was giving the best accuracy on Validation Data so We have used aplit-0 indexes for training the model\n",
    "\n",
    "train_idx=np.load('IndexesFrom10Fold/train_0.npy')\n",
    "test_idx=np.load('IndexesFrom10Fold/test_0.npy')\n",
    "\n",
    "print(\"Train Best indexes Shape: \", train_idx.shape)\n",
    "print(\"Test Best indexes shape: \", test_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2c96353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Best Split Shape:  (7776, 22)\n"
     ]
    }
   ],
   "source": [
    "# Creating the Best Train Data from the Split indexes obtained from the 10 fold cross validation\n",
    "x_train, x_test, y_train, y_test = train_22features_reshaped[train_idx], train_22features_reshaped[test_idx], train_labels[train_idx], train_labels[test_idx]\n",
    "x_train_324x24=x_train.reshape(-1,22)\n",
    "x_test_36x24=x_test.reshape(-1,22)\n",
    "print(\"Train Data Best Split Shape: \",x_train_324x24.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "546e17bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.25555555555555554\n",
      "Class-wise Accuracy: [0.26666667 0.13333333 0.23333333 0.33333333 0.06666667 0.5       ]\n",
      "Mean Class-wise Accuracy: 0.25555555555555554\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "    \n",
    "x_train, x_test, y_train, y_test = train_22features_reshaped[train_idx], train_22features_reshaped[test_idx], train_labels[train_idx], train_labels[test_idx]\n",
    "x_train_324x24=x_train.reshape(-1,22)\n",
    "x_test_36x24=x_test.reshape(-1,22)\n",
    "    \n",
    "# Creating the Train labels according to the Train Data Shape\n",
    "n = 24\n",
    "train_labels_7776 = [item for item in y_train for iii in range(n)]\n",
    "#val_labels_864=[item for item in y_test for jjj in range(n)]\n",
    "\n",
    "# Trainig the Model on the best split Train Data\n",
    "RF_classifier = RandomForestClassifier(random_state=2298, bootstrap= True,max_depth=8,max_features=1.0,max_samples=1.0,min_samples_leaf=2,min_samples_split=7,n_estimators=200)\n",
    "\n",
    "RF_classifier.fit(x_train_324x24, train_labels_7776)\n",
    "\n",
    "# Predicting Using The Validation Data\n",
    "RF_prediction=RF_classifier.predict(val_22features_withoutNan)\n",
    "\n",
    "# Creating the predited labels accoring to the Validation data shape \n",
    "l=0\n",
    "r=24\n",
    "RF_final_pred=[]\n",
    "for ii in range(180):\n",
    "    test_list=list(RF_prediction[l:r])\n",
    "    l=r\n",
    "    r=r+24\n",
    "    res = max(set(test_list), key = test_list.count)\n",
    "    RF_final_pred.append(res)\n",
    "#len(RF_final_pred)\n",
    "\n",
    "#print(\"Fold {0}: {1}\".format(i,accuracy_score(val_labels,RF_final_pred)))\n",
    "\n",
    "overall_acc, classwise_acc = classwise_accuracy(val_labels, RF_final_pred)\n",
    "#overall_acc, classwise_acc = classwise_accuracy(y_true, y_pred)\n",
    "\n",
    "print(\"Overall Accuracy:\", overall_acc)\n",
    "print(\"Class-wise Accuracy:\", classwise_acc)\n",
    "print(\"Mean Class-wise Accuracy:\", np.mean(np.array(classwise_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b1eabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predictions for the Test data (22 Features Data)\n",
    "RF_test_prediction=RF_classifier.predict(test_22Features)\n",
    "\n",
    "l=0\n",
    "r=24\n",
    "RF_test_pred=[]\n",
    "for ii in range(180):\n",
    "    #test_pred_list=list(RF_prediction[l:r])    #### Here it was wrong\n",
    "    test_pred_list=list(RF_test_prediction[l:r])\n",
    "    l=r\n",
    "    r=r+24\n",
    "    res = max(set(test_pred_list), key = test_pred_list.count)\n",
    "    RF_test_pred.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d0df619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['surprise',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'surprise',\n",
       " 'anger',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'surprise',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'disgust',\n",
       " 'joy',\n",
       " 'fear',\n",
       " 'anger',\n",
       " 'surprise',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'joy',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'joy',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'surprise',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'joy',\n",
       " 'fear',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'anger',\n",
       " 'fear',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'joy',\n",
       " 'anger',\n",
       " 'joy',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'anger',\n",
       " 'joy',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'surprise',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'surprise',\n",
       " 'joy',\n",
       " 'surprise',\n",
       " 'fear',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'anger',\n",
       " 'joy',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'disgust',\n",
       " 'disgust',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'sadness',\n",
       " 'fear',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'surprise',\n",
       " 'disgust',\n",
       " 'surprise',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'sadness',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'joy',\n",
       " 'joy',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'anger',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'disgust',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'disgust',\n",
       " 'anger',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'disgust',\n",
       " 'sadness',\n",
       " 'anger',\n",
       " 'sadness',\n",
       " 'sadness',\n",
       " 'sadness']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Mapping the predicted labels to the actual classes\n",
    "import pandas as pd\n",
    "encoding_reverse = {0:'fear', 1:'joy', 2:'anger', 3:'sadness', 4:'disgust',5:'surprise'}\n",
    "\n",
    "test_pred_labels_encoded= [encoding_reverse.get(emotion_pred) for emotion_pred in RF_test_pred]\n",
    "test_pred_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6fd3c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the validation template and create the final Test prediction csv file to upload on the codabench portal\n",
    "\n",
    "validation_filenames=pd.read_csv('fg24_submission_template_test_phase/predictions.csv')['filename']\n",
    "\n",
    "#  Creating DataFrame with two lists\n",
    "csv_to_upload = pd.DataFrame({'filename' : validation_filenames,\n",
    "                                'class' : test_pred_labels_encoded},\n",
    "                                columns=['filename','class'])\n",
    "\n",
    "csv_to_upload.to_csv('Test_Predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b671cbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user03_raw_01.csv</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user03_raw_02.csv</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user03_raw_03.csv</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user03_raw_04.csv</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user03_raw_05.csv</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>user32_raw_14.csv</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>user32_raw_15.csv</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>user32_raw_16.csv</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>user32_raw_17.csv</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>user32_raw_18.csv</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              filename     class\n",
       "0    user03_raw_01.csv  surprise\n",
       "1    user03_raw_02.csv      fear\n",
       "2    user03_raw_03.csv       joy\n",
       "3    user03_raw_04.csv      fear\n",
       "4    user03_raw_05.csv      fear\n",
       "..                 ...       ...\n",
       "175  user32_raw_14.csv   sadness\n",
       "176  user32_raw_15.csv     anger\n",
       "177  user32_raw_16.csv   sadness\n",
       "178  user32_raw_17.csv   sadness\n",
       "179  user32_raw_18.csv   sadness\n",
       "\n",
       "[180 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_to_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc11b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
